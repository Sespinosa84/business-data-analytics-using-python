{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red>Introduction to Business Analytics:<br>Using Python for Better Business Decisions</font>\n",
    "=======\n",
    "<br>\n",
    "    <center><img src=\"http://dataanalyticscorp.com/wp-content/uploads/2018/03/logo.png\"></center>\n",
    "<br>\n",
    "Taught by: \n",
    "\n",
    "* Walter R. Paczkowski, Ph.D. \n",
    "\n",
    "    * My Affliations: [Data Analytics Corp.](http://www.dataanalyticscorp.com/) and [Rutgers University](https://economics.rutgers.edu/people/teaching-personnel)\n",
    "    * [Email Me With Questions](mailto:walt@dataanalyticscorp.com)\n",
    "    * [Learn About Me](http://www.dataanalyticscorp.com/)\n",
    "    * [See My LinkedIn Profile](https://www.linkedin.com/in/walter-paczkowski-a17a1511/)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue> Lesson \\#2:<br>Data Visualization for Insight</font>\n",
    "\n",
    "In this lesson, you will learn:\n",
    "\n",
    "1. some fundamentals for visualizing your data; and\n",
    "2. how to interpret basic graphs common in Business Analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> Reset the Data from Lesson 1 </font>\n",
    "\n",
    "Resetting the data will ensure that the work you did in Lesson 1 is available in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Load packages\n",
    "##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "##\n",
    "## Import the data.  The parse_dates argument says to \n",
    "## treat Tdate as a date object.\n",
    "##\n",
    "file = r'../data/orders.csv'\n",
    "df_orders = pd.read_csv( file, parse_dates = [ 'Tdate' ] )\n",
    "pd.set_option('display.max_columns', 8)\n",
    "##\n",
    "## Initial Calculations\n",
    "##\n",
    "x = [ 'Ddisc', 'Odisc', 'Cdisc', 'Pdisc' ]\n",
    "df_orders[ 'Tdisc' ] = df_orders[ x ].sum( axis = 1 )\n",
    "##\n",
    "df_orders[ 'Pprice' ] = df_orders.Lprice*( 1 - df_orders.Tdisc )\n",
    "##\n",
    "df_orders[ 'Rev' ] = df_orders.Usales * df_orders.Pprice\n",
    "##\n",
    "df_orders[ 'Con' ] = df_orders.Rev - df_orders.Mcost\n",
    "df_orders[ 'CM' ] = df_orders.Con/df_orders.Rev\n",
    "##\n",
    "df_orders[ 'netRev' ] = ( df_orders.Usales - df_orders.returnAmount )*df_orders.Pprice\n",
    "df_orders[ 'lostRev' ] = df_orders.Rev - df_orders.netRev\n",
    "##\n",
    "##\n",
    "## Import a second DataFrame on the customers\n",
    "##\n",
    "file = r'../data/customers.csv'\n",
    "df_cust = pd.read_csv( file )\n",
    "##\n",
    "## Do an inner join using CID as the link\n",
    "##\n",
    "df = pd.merge( df_orders, df_cust, on = 'CID' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> Look at the Distribution of Your Data </font>\n",
    "\n",
    "In this section, you will learn to use\n",
    "\n",
    "- *histograms*;\n",
    "- *boxplots*;\n",
    "- *kernel density plots*; and\n",
    "- *hex bin plots*\n",
    "\n",
    "to visualize your data.  The focus is on scientific visualization rather than infographics visualization.      \n",
    "\n",
    "**Case Study Problem**:\n",
    "<br><br>\n",
    "The product manager wanted to know about sales patterns by:\n",
    "\n",
    "- Marketing Region\n",
    "- Customer Loyalty\n",
    "- Buyer Rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Marketing Region Analysis </font>\n",
    "\n",
    "Check the region counts.  This is a simple step to answer the question \"*How many orders are there by marketing region*?\" so it should be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Use value_counts() method\n",
    "##\n",
    "df.Region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Use value_counts() method\n",
    "## Use the \"normalize = True\" argument to get proportions\n",
    "## Recommendation: always round proportions to 3 decimal places \n",
    "##\n",
    "round( df.Region.value_counts( normalize = True ), 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Exercises </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color = black> Exercise \\#2.1 </font>\n",
    "\n",
    "Check the Customer Loyalty and Buyer Rating counts and proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Enter code here: Customer Loyalty\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Enter code here: Buyer Rating\n",
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Histograms </font>\n",
    "\n",
    "You can use a histogram to examine the distribution of unit sales and the total discount calculated above.  Notice in the following display that a smooth line is overlayed.  This is a *kernel density estimate* (*KDE*).  You will see this again shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## histogram of unit sales\n",
    "##\n",
    "ax = sns.distplot( df.Usales )\n",
    "ax.set( title = \"Unit Sales Distribution\", xlabel = 'Unit Sales', \n",
    "       ylabel = 'Proportions' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distrbution is highly skewed to the right which distorts the impression of the data.  Using the natural log will normalize the display.  This is helpful so when you model unit sales you should use a log transformation.  This next graph shows that the distribution (on a log scale) is fairly normal.\n",
    "\n",
    "**Recommendation**: use the Numpy *log1p* function.  This returns the natural log of one plus the argument: $np.log1p( x ) = log_e(1 + x)$.  The reason for using this function is to avoid cases where $x = 0$: $log(0)$ is undefined, which is meaningless, but $log( 1 ) = 0$ so you would have a meaningful number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Plot the natural log of unit sales\n",
    "## A KDE curve is included by default\n",
    "##\n",
    "ax = sns.distplot( np.log1p( df.Usales) )\n",
    "ax.set( title = \"Unit Sales Distribution: Log Scale\", \n",
    "       xlabel = 'Unit Sales (Natural Log)',\n",
    "       ylabel = 'Proportions' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a *rug plot* to the bottom of the histogram to show each observation.  This is helpful to show where the data are for each bar in the histogram.  This, of course, is not practical for large data sets since the rug would just be a dense, black bar at the bottom of the graph.  \n",
    "<br><br>\n",
    "You can also remove the *KDE* curve for a better visualization of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Add a rug and remove the KDE\n",
    "##\n",
    "ax = sns.distplot( np.log( df.Usales), kde = False, rug = True )\n",
    "ax.set( title = \"Unit Sales Distribution: Log Scale\", \n",
    "       xlabel = 'Unit Sales (Natural Log)', \n",
    "       ylabel = 'Proportions' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display just the *KDE* curve for a cleaner view of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## KDE only\n",
    "##\n",
    "ax = sns.distplot( np.log( df.Usales), hist = False )\n",
    "ax.set( title = \"Unit Sales Distribution: Log Scale\", \n",
    "       xlabel = 'Unit Sales (Natural Log)', \n",
    "       ylabel = 'Proportions' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks very much like a normal distribution.  This will be important for *OLS* modeling which relies on normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Boxplots </font>\n",
    "\n",
    "Boxplots are the most useful visualization tool for examining distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Pocket price distribution with boxplots\n",
    "## By regions\n",
    "##\n",
    "ax = sns.boxplot( y = 'Tdisc', data = df[ df.Region == 'Northeast' ] )\n",
    "ax.set( title = 'Distribution of Total Discount', ylabel = 'Total Discount' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Total Discount is symmetrically distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Total discount distribution by regions\n",
    "##\n",
    "ax = sns.boxplot( x = 'Region', y = 'Tdisc', data = df )\n",
    "ax.set( title = 'Distribution of Total Discount by Region', ylabel = 'Total Discount', \n",
    "       xlabel = 'Marketing Regions' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that discounts are the lowest in the Southern Region while the Midwest has a large number of very low discounts.  Also, the dispersion of the discounts in the Southern Region is small relative to that in the other three regions.  Let us drill down to verify the differences for the Southern Region.  Use Tukey's pairwise *HSD* test for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## \n",
    "## Compare the mean for each region using\n",
    "## a multiple comparison test: Tukey's pairwise HSD test.\n",
    "## Since there are four regions, there are six pairs.\n",
    "##\n",
    "## Load the multiple comparison package from statamodels\n",
    "##\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "##\n",
    "## Do the test.  The Null Hypothesis is no difference for each pair.\n",
    "##\n",
    "x = x = [ 'Region', 'Tdisc' ]\n",
    "tmp = df[ x ]\n",
    "tukey = pairwise_tukeyhsd( endog = tmp.Tdisc,     # Data\n",
    "                          groups = tmp.Region,    # Groups\n",
    "                          alpha = 0.05 )          # Significance level\n",
    "print( '\\nHull Hypothesis: No Difference in Pairwise Means' )\n",
    "tukey.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in the means is $meandiff = group2 - group1$. Notice that the Null Hypothesis is rejected for all combinations of the Southern Region and the other three (the last row of the table should be reversed to be consistent with the other Southern comparisons).  Also notice that the difference in the means for the Southern Region is negative in all cases.\n",
    "\n",
    "We can look at the summary statistics by region using Pandas' *groupby* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Group the total discount by region and then use the describe\n",
    "## function on the groups.\n",
    "##\n",
    "df.Tdisc.groupby( df.Region ).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drill down on the discounts in the Southern Region\n",
    "##\n",
    "## Select the discounts for the Southern Region\n",
    "##\n",
    "x = [ 'Ddisc', 'Cdisc', 'Odisc', 'Pdisc' ]\n",
    "df_south = df.loc[ df.Region == 'South', x ]\n",
    "##\n",
    "## Use a boxplot to examine the distributions.\n",
    "##\n",
    "ax = sns.boxplot(x = \"variable\", y = \"value\", data = pd.melt( df_south ) )\n",
    "ax.set( title = 'Discount Distribution\\nSouthern Marketing Region', \n",
    "       xlabel = 'Type of Discount',\n",
    "      ylabel = 'Discount Amount')\n",
    "##\n",
    "## Reset the tick labels to more meaningful labels\n",
    "##\n",
    "ax.set_xticklabels( [ 'Dealer', 'Order\\nSize', 'Competitive', 'Pickup' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dealer discount tends to be the largest while the order discount has the most variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Compare the mean for each discount type using\n",
    "## a multiple comparison test: Tukey's pairwise HSD test.\n",
    "## Since there are four discounts, there are six pairs.\n",
    "##\n",
    "## First, convert the data from wide- to-long form\n",
    "## using the Pandas melt function.  This returns a DataFrame\n",
    "## with two columns: a label and a value.\n",
    "##\n",
    "df_melt = pd.melt( df_south )\n",
    "##\n",
    "## Do the test.  The Null Hypothesis is no difference for each pair.\n",
    "##\n",
    "tukey = pairwise_tukeyhsd(endog = df_melt.value,       # Data\n",
    "                          groups = df_melt.variable,   # Groups\n",
    "                          alpha=0.05)                          # Significance level\n",
    "print( '\\nHull Hypothesis: No Difference in Pairwise Means: Southern Region' )\n",
    "tukey.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Exercises </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color = black> Exercise \\#2.2 </font> \n",
    "\n",
    "Examine the Midwestern region.  This is more complicated since there are missing values in the Midwest.  First use *df.dropna( axis = 0, inplace = True )* to remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Example\n",
    "## Drop all rows with at least one missing value\n",
    "## This example uses a temporary DataFrame\n",
    "##\n",
    "x = [ 'Tdisc', 'Ddisc', 'Cdisc', 'Odisc', 'Pdisc' ]\n",
    "tmp = df.loc[ df.Region == 'Midwest', x ]\n",
    "##\n",
    "## Before\n",
    "##\n",
    "print( '\\nBefore:\\n' )\n",
    "print( tmp.info() )\n",
    "##\n",
    "## After\n",
    "##\n",
    "tmp.dropna( inplace = True )  ## axis = 0 is the default \n",
    "print( '\\nAfter:\\n' )\n",
    "print( tmp.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Enter code here.  Insert cells below this if needed.\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Compare the mean for each discount type using\n",
    "## a multiple comparison test: Tukey's pairwise HSD test.\n",
    "## Since there are four discounts, there are six pairs.\n",
    "##\n",
    "## Melt or stack the DataFrame\n",
    "##\n",
    "df_melt = pd.melt( df_midwest )\n",
    "##\n",
    "## Do the test.  The Null Hypothesis is no difference for each pair.\n",
    "## \n",
    "tukey = pairwise_tukeyhsd( endog = df_melt.value,      # Data\n",
    "                          groups = df_melt.variable,   # Groups\n",
    "                          alpha=0.05)              # Significance level\n",
    "print( '\\nHull Hypothesis: No Difference in Pairwise Means: Midwestern Region' )\n",
    "tukey.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the discounts by the customer loyalty status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Total discount distribution by regions and Loyalty Program\n",
    "## members\n",
    "##\n",
    "ax = sns.boxplot( x = 'Region', y = 'Tdisc', hue = 'loyaltyProgram', data = df )\n",
    "ax.set( title = 'Distribution of Total Discount by Region \\n and \\n Loyalty Program',\n",
    "       ylabel = 'Total Discount' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Another view of total discount distribution by Regions and Loyalty Program\n",
    "## members\n",
    "##\n",
    "ax = sns.catplot(x = 'Tdisc', y = 'loyaltyProgram', row = 'Region',\n",
    "                kind = 'box', orient = 'h', height = 1.5, aspect = 4,\n",
    "                data = df )\n",
    "ax.set(  xlabel = 'Total Discount', ylabel = 'Loyalty Program\\nMember'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be disturbing that the discounts are the same whether a customer is in the loyalty program or not.  Members should have bigger discounts.  What about how they are rated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Total discount distribution by regions and buyer rating\n",
    "##\n",
    "ax = sns.boxplot( x = 'Region', y = 'Tdisc', hue = 'buyerRating', data = df )\n",
    "ax.set( title = 'Distribution of Total Discount by Region \\n and \\n Buyer Rating', \n",
    "       ylabel = 'Total Discount' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loyalty and good ratings are not rewarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Exercises </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color = black> Exercise \\#2.3 </font> \n",
    "\n",
    "Examine the distribution of net revenue by region, loyalty program, and buyer rating.  What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Enter code here\n",
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> Look for Relationships in Your Data </font> \n",
    "\n",
    "Scatter plots are the workhorse of statistical displays because they allow you to see relationships -- sometimes.  Properly drawn, they can provide a wealth of insight into the \n",
    "\n",
    "- relationships\n",
    "- trends\n",
    "- patterns\n",
    "- anomalies\n",
    "\n",
    "of two continuous variables.  They can be supplemented with histograms on the margins to show distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Transformation for Better Interpretation </font>\n",
    "\n",
    "Since one objective from the product manager is to estimate a price elasticity, you should graph unit sales and Pocket Price.  We did notice earlier that unit sales were right skewed but that using a log transform shifted the distribution to a more normal one.  We should take the log of unit sales as well as pocket price.  This is a very common transformation in empirical demand analysis because the slope of a line is the elasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Transform unit sales and pocket price\n",
    "##\n",
    "df[ 'log_Pprice' ] = np.log1p( df.Pprice )\n",
    "df[ 'log_Usales' ] = np.log1p( df.Usales )\n",
    "##\n",
    "## Display the unlogged and logged data\n",
    "##\n",
    "x = [ 'Pprice', 'log_Pprice', 'Usales', 'log_Usales' ]\n",
    "##df.loc[ :, x ].head()\n",
    "df[ x ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Plot the logged data\n",
    "## Use the Seaborn \"relplot\" function\n",
    "##\n",
    "ax = sns.relplot( x = 'log_Pprice', y = 'log_Usales', data = df )\n",
    "ax.set( title = 'Unit Sales vs. Pocket Price\\nLog Scales', xlabel = 'Pocket Price', \n",
    "       ylabel = 'Unit Sales' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative relationship is evident -- as it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Enhancing the Scatter Plot </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Replot the logged data with a regression line added. \n",
    "## Use the Seaborn \"regplot\" function.\n",
    "##\n",
    "## Warning -- this will take a few seconds\n",
    "##\n",
    "ax = sns.regplot( x = 'log_Pprice', y = 'log_Usales', data = df )\n",
    "ax.set( title = 'Unit Sales vs. Pocket Price\\nLog Scales', \n",
    "       xlabel = 'Pocket Price', ylabel = 'Unit Sales' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Adding a Categorical Variable </font>\n",
    "\n",
    "You can add a third variable that is categorical to show relationships across groups.  This is done with a \"hue\" command which colors the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Add Loyalty Program membership\n",
    "##\n",
    "## Warning -- this will take a few seconds\n",
    "##\n",
    "ax = sns.relplot( x = 'log_Pprice', y = 'log_Usales', hue = 'loyaltyProgram', \n",
    "                 data = df )\n",
    "ax.set( title = 'Unit Sales vs. Pocket Price\\nLog Scales', \n",
    "       xlabel = 'Pocket Price', \n",
    "       ylabel = 'Unit Sales' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Add Region\n",
    "##\n",
    "## Warning -- this will take a few seconds\n",
    "##\n",
    "ax = sns.relplot( x = 'log_Pprice', y = 'log_Usales', hue = 'Region', data = df )\n",
    "ax.set( title = 'Unit Sales vs. Pocket Price\\nLog Scales', \n",
    "       xlabel = 'Pocket Price', ylabel = 'Unit Sales' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Add Loyalty Program membership\n",
    "## A less cluttered view with panels\n",
    "##\n",
    "## Warning -- this will take a few seconds\n",
    "##\n",
    "ax = sns.relplot( x = 'log_Pprice', y = 'log_Usales', hue = 'loyaltyProgram', \n",
    "                 col = 'Region', col_wrap = 2,\n",
    "                 data = df )\n",
    "ax.set( xlabel = 'Pocket Price', ylabel = 'Unit Sales' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the gap between 17 and 19 in the Northeast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Combining Scatter Plots and Histograms </font>\n",
    "\n",
    "You can combine scatter plots with histograms for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Add histograms to the margins\n",
    "##\n",
    "ax = sns.jointplot( x = 'log_Pprice', y = 'log_Usales', data = df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Pairwise Scatter Plots </font>\n",
    "\n",
    "You can also plot multiple variables in pair-wise combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Use the Seaborn pairwise function\n",
    "##\n",
    "x = [ 'Ddisc', 'Cdisc', 'Odisc', 'Pdisc' ]\n",
    "##\n",
    "## We know there are missing values for the discounts.\n",
    "## Missing values are not handled well with Seaborn histograms.\n",
    "## So drop all records with any missing data.\n",
    "##\n",
    "tmp = df[ x ].copy()\n",
    "tmp.dropna( inplace = True )\n",
    "sns.pairplot( tmp[ x ] )\n",
    "##\n",
    "## Warning -- this will take a few minutes\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular plot is clearly not useful because the data set is large; we have a case of *Large-N*.  So how is this handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = black> Working with *Large-N* Data </font>\n",
    "\n",
    "The scatter plots are dense, making it difficult to see some patterns. Options are:\n",
    "\n",
    "- random sample\n",
    "- contour plot\n",
    "- hex plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = df.sample( n = 1000 )\n",
    "ax = sns.relplot( x = 'log_Pprice', y = 'log_Usales', data = smpl,\n",
    "                 kind = \"scatter\" )\n",
    "ax.set( title = 'Sales vs. Pocket Price\\nRandom Sample', \n",
    "       ylabel = 'Log Unit Sales', xlabel = 'Log Pocket Price' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Pairwise plot based on a random sample\n",
    "##\n",
    "x = [ 'Ddisc', 'Cdisc', 'Odisc', 'Pdisc' ]\n",
    "sns.pairplot( smpl[ x ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much better.  Maybe a smaller sample will work.  You can try this on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Contour plot with margnal distributions\n",
    "## Random sample\n",
    "##\n",
    "## Warning -- this will take a minute\n",
    "##\n",
    "ax = sns.jointplot( x = 'log_Pprice', y = 'log_Usales', data = smpl, kind = \"kde\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hex Bin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Hex binning\n",
    "## Random sample\n",
    "## Note: A white background is best for this \n",
    "## Note: The plot element colors can be set: b:blue, \n",
    "##   g:green, r:red, c:cyan, m:magenta, y:yellow,\n",
    "##   k:black, w:white.\n",
    "##\n",
    "## Warning -- this will take a minute\n",
    "##\n",
    "with sns.axes_style( 'white' ):\n",
    "    ax = sns.jointplot(x = 'log_Pprice', y = 'log_Usales', data = smpl, \n",
    "                       kind=\"hex\", color = 'k' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Hex binning\n",
    "## Full data set\n",
    "## Note: A white background is best for this \n",
    "## Note: The plot element colors can be set: b:blue, \n",
    "##   g:green, r:red, c:cyan, m:magenta, y:yellow,\n",
    "##   k:black, w:white.\n",
    "##\n",
    "## Warning -- this will take a minute\n",
    "##\n",
    "with sns.axes_style( 'white' ):\n",
    "    ax = sns.jointplot(x = 'log_Pprice', y = 'log_Usales', data = df, \n",
    "                       kind=\"hex\", color = 'k' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Add a regression line\n",
    "## Full data set\n",
    "##\n",
    "## Warning -- this will take a minute\n",
    "##\n",
    "with sns.axes_style(\"white\"):\n",
    "    g = sns.jointplot( x = 'log_Pprice', y = 'log_Usales', data = df, \n",
    "                      kind = 'hex', color = 'k',\n",
    "                      joint_kws={'gridsize':40, 'bins':'log'} )\n",
    "    ax = sns.regplot( x = 'log_Pprice', y = 'log_Usales', data = df, \n",
    "                     ax = g.ax_joint, scatter = False )\n",
    "    ax.set( xlabel = 'Log Pocket Price', ylabel = 'Log Unit Sales' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Exercises </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = black> Exercise \\#2.4 </font>\n",
    "\n",
    "Study the relationship between any two variables of your choice.  What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Enter code here.  Insert cells below this if needed.\n",
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> Look for Trends in Your Data </font> \n",
    "\n",
    "Trends are identified using line graphs, usually with time on the X-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Subset the date indicator and the Dealer Discount\n",
    "##\n",
    "x = [ 'Tdate', 'Ddisc' ]\n",
    "tmp = df_orders[ x ].copy()\n",
    "##\n",
    "## Reset the index to the date\n",
    "##\n",
    "tmp.set_index( 'Tdate', inplace = True )\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Group the data by months and calculate the \n",
    "## mean discount for each month.\n",
    "##\n",
    "grp = tmp.groupby( pd.Grouper( freq = \"M\" ) ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Use the Seaborn lineplot function\n",
    "##\n",
    "ax = sns.lineplot( y = 'Ddisc', x = grp.index, data = grp )\n",
    "ax.set( title = 'Dealer Discount\\nMonthly', ylabel = 'Dealer Discount', xlabel = 'Months' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## An alternative way to plot uses Pandas' plot function.\n",
    "## It automatically uses the index for the X-axis.\n",
    "##\n",
    "ax = grp.plot( y = 'Ddisc' , legend = False )\n",
    "ax.set( title = 'Dealer Discount\\nMonthly', ylabel = 'Dealer Discount', xlabel = 'Months' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in the two time series plots.  Seaborn connects the points even if a point is missing; Pandas does not. Pandas gives a better representation and is better with time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> Look for Anomalies in Your Data </font> \n",
    "\n",
    "The boxplots are good for this.  You can also see odd data points in distribution plots (histograms and boxplots), scatter plots, and time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Categorical plot: boxplot\n",
    "##\n",
    "ax = sns.catplot( 'Tdisc', kind = 'box', orient = 'v', data = df_orders )\n",
    "ax.set( title = 'Total Discount\\nOutliers', ylabel = 'Total Discount', xlabel = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = black> What's Next? </font>\n",
    "\n",
    "In Lesson 3, I will show you how to build two predictive models:\n",
    "\n",
    "1. *OLS*; and\n",
    "2. Logit.\n",
    "\n",
    "I'll discuss these in the next lesson.\n",
    "<br><br><br>\n",
    "<font color = red, size = \"+3\"><b> Five Minute Break </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
